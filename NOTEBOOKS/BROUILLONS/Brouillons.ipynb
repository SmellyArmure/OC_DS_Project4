{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "df_res = pd.DataFrame(dtype = 'object')\n",
    "\n",
    "dict_param_grid = {'KNN': {'n_neighbors': [1,2,3,5,7,9,11]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting parameters\n",
    "reg = KNeighborsRegressor()\n",
    "name_reg = 'KNN'\n",
    "param_grid = {str(reg)[:-2].lower()+'__'+k : v \\\n",
    "              for k,v in dict_param_grid[name_reg].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# researching best hyperparameters and fitting on training set\n",
    "pipe = make_pipeline(column_trans, reg)\n",
    "gscv = GridSearchCV(pipe,\n",
    "                    param_grid=param_grid,\n",
    "                    cv=kf, verbose=1)\n",
    "gscv.fit(X_tr,y1_tr)\n",
    "\n",
    "# best hyperparams\n",
    "df_res = pd.DataFrame(dtype = 'object')\n",
    "df_res.loc['name_params', name_reg] = tuple([k for k,v in dict_param_grid[name_reg].items()])\n",
    "df_res.loc['best_params', name_reg] = tuple([gscv.best_params_[p] for p in param_grid])\n",
    "\n",
    "# score of the model with best params on testing set\n",
    "y_pr = gscv.predict(X_te)\n",
    "res = scores_reg(name_reg, X_te, y1_te, y_pr).astype('object')\n",
    "df_res = df_res.append(res.to_frame())\n",
    "\n",
    "# mean cv score of the model with best params on testing set\n",
    "res = cv_scores_reg(name_reg, gscv.best_estimator_, X_te, y1_te, cv=6).astype('object')\n",
    "df_res = df_res.append(res.to_frame())\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting optimisation curve of hyperparameters\n",
    "\n",
    "\n",
    "list_n_params = [n for n in gscv_res.keys()if 'param_' in n]\n",
    "list_params = [gscv.cv_results_[p].tolist() for p in list_n_params]\n",
    "for n_p, li_p in zip(list_n_params, list_params):\n",
    "    plt.errorbar(li_p,\n",
    "            gscv.cv_results_['mean_test_score'],\n",
    "            yerr=gscv.cv_results_['std_test_score'])\n",
    "    plt.gcf().suptitle(n_p)\n",
    "# plt.gca().set_xscale('log')\n",
    "# plt.gca().set(xlim=(0,10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "name_reg = 'LinReg(allcols)'\n",
    "\n",
    "pipe = make_pipeline(column_trans, reg)\n",
    "pipe.fit(X_tr,y1_tr)\n",
    "\n",
    "y_pr = pipe.predict(X_te)\n",
    "\n",
    "res = scores_reg(name_reg, X_te, y1_te, y_pr).astype('object')\n",
    "df_lr = df_lr.append(res.to_frame())\n",
    "res = cv_scores_reg(name_reg, pipe,\n",
    "                    X_te, y1_te, cv=6).astype('object')\n",
    "df_lr = df_lr.append(res.to_frame())\n",
    "\n",
    "df_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting optimisation curve of hyperparameters\n",
    "param_grid = dict_param_grid[name_reg]\n",
    "\n",
    "gscv_res = knn_gscv.cv_results_\n",
    "list_n_params = [n for n in gscv_res.keys()if 'param_' in n]\n",
    "list_params = [gscv_res[p].tolist() for p in list_n_params]\n",
    "for n_p, li_p in zip(list_n_params, list_params):\n",
    "    plt.errorbar(li_p,\n",
    "            gscv_res['mean_test_score'],\n",
    "            yerr=gscv_res['std_test_score'])\n",
    "    plt.gcf().suptitle(n_p)\n",
    "# plt.gca().set_xscale('log')\n",
    "# plt.gca().set(xlim=(0,10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = ElasticNet()\n",
    "name_reg = 'my_enet'\n",
    "dict_param_grid = {'my_enet': {'alpha': [1,15],\n",
    "                               'l1_ratio': [0.3,0.5]}}\n",
    "kf_gscv = KFold(n_splits=2, shuffle=True)\n",
    "\n",
    "# version unique\n",
    "enet_gscv, new_df_res = model_optimizer(name_reg=name_reg, data_preproc=column_trans,\n",
    "                                 reg=reg, param_grid=dict_param_grid[name_reg],\n",
    "                                 Xtr=X_tr, ytr=y1_tr, Xte=X_te, yte=y1_te,\n",
    "                                 cv_gs=kf_gscv, cv_test=6)\n",
    "df_res = pd.concat([df_res, new_df_res], axis=1)\n",
    "\n",
    "display(df_res)\n",
    "\n",
    "plot_2D_hyperparam_opt(enet_gscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "name_reg = 'LinReg(allcols)'\n",
    "\n",
    "pipe = make_pipeline(column_trans, reg)\n",
    "pipe.fit(X_tr,y1_tr)\n",
    "\n",
    "y_pr = pipe.predict(X_te)\n",
    "\n",
    "ser = scores_reg(name_reg, X_te_sel, y1_te, y_pr).astype('object')\n",
    "ser = ser.append(cv_scores_reg(name_reg, pipe, X_te_sel, y1_te, cv=6).astype('object'))\n",
    "\n",
    "df_lr = df_lr.append(ser.to_frame())\n",
    "\n",
    "df_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_reg = name_reg\n",
    "# pipe= pipe\n",
    "# Xte = X_te\n",
    "# yte = y1_te\n",
    "# df_res=df_lr\n",
    "# cv=5\n",
    "\n",
    "# if df_res is None:\n",
    "#     df_res = pd.DataFrame(dtype = 'object')\n",
    "# df_res_mod = pd.DataFrame(dtype = 'object')\n",
    "# ypr = pipe.predict(Xte)\n",
    "# ser = scores_reg(name_reg, Xte, yte, ypr).astype('object')\n",
    "# ser = ser.append(cv_scores_reg(name_reg, pipe, Xte, yte, cv=cv).astype('object'))\n",
    "# df_res_mod = pd.concat([df_res,ser.to_frame()],1)\n",
    "# df_res_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_append_curve(x, y, c, fig=None):\n",
    "    %matplotlib\n",
    "    if fig is None:\n",
    "        fig = plt.figure()\n",
    "    ax = fig.axes[0]\n",
    "    ax.plot(x, y, c=c)\n",
    "    %matplotlib inline\n",
    "    return fig\n",
    "\n",
    "fig = plot_append_curve([100,11,90,13], [100,90,70,200], c='grey', fig=fig);\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD VERSION\n",
    "class CustEncoder(BaseEstimator) :\n",
    "\n",
    "    def __init__(self, l_card_cols, h_card_cols, bool_cols,\n",
    "                 strat_low_card='ord', strat_high_card='ord'):\n",
    "        self.l_card_cols = l_card_cols\n",
    "        self.h_card_cols = h_card_cols\n",
    "        self.bool_cols = bool_cols\n",
    "        self.strat_low_card = strat_low_card\n",
    "        self.strat_high_card = strat_high_card\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Dictionary to translate strategies\n",
    "        d_enc = {'ohe': ce.OneHotEncoder(),\n",
    "                 'hash': ce.HashingEncoder(),\n",
    "                 'ord': ce.OrdinalEncoder(),\n",
    "                 'loo': ce.LeaveOneOutEncoder(),\n",
    "                 'bin': ce.BinaryEncoder()}\n",
    "\n",
    "        # Creates a columns transformer with chosen strategies\n",
    "        self.column_trans = ColumnTransformer([(\"low_card\", d_enc[self.strat_low_card], l_card_cols),\n",
    "                                       (\"bool\", ce.OrdinalEncoder(), bool_cols),\n",
    "                                       (\"high_card\", d_enc[self.strat_high_card], h_card_cols)],\n",
    "                                       remainder=StandardScaler())\n",
    "        return self.column_trans.fit(X, y)\n",
    "  \n",
    "    def transform(self, X, y=None):\n",
    "        return  self.column_trans.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = knn_gscv3.cv_results_\n",
    "scoring = ['neg_root_mean_squared_error', 'r2']\n",
    "param = 'param_KNN3__n_neighbors'\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\",\n",
    "          fontsize=16)\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"Score\")\n",
    "ax = plt.gca()\n",
    "\n",
    "# Get the regular numpy array from the MaskedArray\n",
    "X_axis = np.array(results[param].data, dtype=float)\n",
    "\n",
    "for scorer, color in zip(sorted(scoring), ['g', 'k']):\n",
    "    for sample, style in (('train', '--'), ('test', '-')):\n",
    "        sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n",
    "        sample_score_std = results['std_%s_%s' % (sample, scorer)]\n",
    "        ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n",
    "                        sample_score_mean + sample_score_std,\n",
    "                        alpha=0.1 if sample == 'test' else 0, color=color)\n",
    "        ax.plot(X_axis, sample_score_mean, style, color=color,\n",
    "                alpha=1 if sample == 'test' else 0.7,\n",
    "                label=\"%s (%s)\" % (scorer, sample))\n",
    "\n",
    "    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
    "    best_score = results['mean_test_%s' % scorer][best_index]\n",
    "\n",
    "    # Plot a dotted vertical line at the best score for that scorer marked by x\n",
    "    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n",
    "            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n",
    "\n",
    "    # Annotate the best score for that scorer\n",
    "    ax.annotate(\"%0.2f\" % best_score, \n",
    "                (X_axis[best_index]+0.5, best_score + 0.005))\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustTransformer(BaseEstimator) :\n",
    "\n",
    "    def __init__(self, thresh_card=12,\n",
    "                 strat_binary = 'ord', strat_low_card ='ohe',\n",
    "                 strat_high_card ='hash', strat_quant = 'stand'):\n",
    "        self.thresh_card = thresh_card\n",
    "        self.strat_binary = strat_binary\n",
    "        self.strat_low_card = strat_low_card\n",
    "        self.strat_high_card = strat_high_card\n",
    "        self.strat_quant = strat_quant\n",
    "\n",
    "    def d_type_col(self, X):\n",
    "        bin_cols = (X.nunique()[X.nunique()==2].index)\n",
    "        X_C_cols = X.select_dtypes(include=['object', 'category'])\n",
    "        C_l_card_cols = X_C_cols.nunique()[X_C_cols.nunique()<self.thresh_card].index\n",
    "        C_h_card_cols = X_C_cols.nunique()[X_C_cols.nunique()>=self.thresh_card].index\n",
    "        Q_cols = [c for c in X.select_dtypes(include=[np.number]).columns\\\n",
    "                                                        if c not in bin_cols]\n",
    "        d_t = {'binary': bin_cols,\n",
    "               'low_card': C_l_card_cols,\n",
    "               'high_card': C_h_card_cols,\n",
    "               'remaind': Q_cols}\n",
    "        return d_t\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Dictionary to translate strategies\n",
    "        d_enc = {'ohe': ce.OneHotEncoder(),\n",
    "                 'hash': ce.HashingEncoder(),\n",
    "                 'ord': ce.OrdinalEncoder(),\n",
    "                 'loo': ce.LeaveOneOutEncoder(),\n",
    "                 'bin': ce.BinaryEncoder(),\n",
    "                 'stand': StandardScaler(),\n",
    "                 'minmax': MinMaxScaler(),\n",
    "                 'maxabs': MaxAbsScaler(),\n",
    "                 'robust': RobustScaler(quantile_range=(25, 75)),\n",
    "                 'norm': Normalizer(),\n",
    "                 'quant_uni': QuantileTransformer(output_distribution='uniform'),\n",
    "                 'quant_norm': QuantileTransformer(output_distribution='normal'),\n",
    "                 'pow': PowerTransformer(method='yeo-johnson'), # 'boxcox'\n",
    "                 }\n",
    "        # Creates a columns transformer with chosen strategies\n",
    "        self.column_trans = \\\n",
    "                ColumnTransformer([(\"binary\", d_enc[self.strat_binary],\n",
    "                                    self.d_type_col(X)['binary']),\n",
    "                                   (\"low_card\", d_enc[self.strat_low_card],\n",
    "                                    self.d_type_col(X)['low_card']),\n",
    "                                   (\"high_card\", d_enc[self.strat_high_card],\n",
    "                                    self.d_type_col(X)['high_card']),\n",
    "                                   (\"remaind\", d_enc[self.strat_quant],\n",
    "                                    self.d_type_col(X)['remaind'])])\n",
    "        return self.column_trans.fit(X, y)\n",
    "  \n",
    "    def transform(self, X, y=None):\n",
    "        return  self.column_trans.transform(X)\n",
    "''' create a pipeline with datapreprocessing column transformer and regressor\n",
    "    then searches for best hyperparameters with gscv\n",
    "    then stores best parameters\n",
    "    then computes the scores of the model on testing set\n",
    "    then computes the cv scores of the model on testing set'''\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def model_optimizer(data_preproc, name_reg, reg, param_grid,\n",
    "                    Xtr, ytr, Xte, yte,\n",
    "                    cv_search=5, groups=None, cv_test=6,\n",
    "                    gs_score='neg_root_mean_squared_error',\n",
    "                    search_strat='grid', n_iter=10):\n",
    "\n",
    "    pipe = Pipeline([('preproc', data_preproc),\n",
    "                    (name_reg, reg)])\n",
    "    \n",
    "    # researching best hyperparameters and fitting on training set\n",
    "    if search_strat=='grid':\n",
    "        scv = GridSearchCV(pipe, param_grid = param_grid,\n",
    "                           cv=cv_search, scoring=gs_score, verbose=1)\n",
    "        print(\"grid\")\n",
    "    elif search_strat=='rand':\n",
    "        scv = RandomizedSearchCV(pipe, param_distributions = param_grid,\n",
    "                            cv=cv_search, n_iter= n_iter,\n",
    "                            scoring=gs_score, verbose=1)\n",
    "        print(\"randomized\")\n",
    "    else:\n",
    "        print(\"ERROR: This strategy of hyperparameter tuning does not exist.\")\n",
    "    scv.fit(Xtr, ytr, groups=groups) # to stratify the folds using a GroupFolds\n",
    "\n",
    "    # best hyperparams\n",
    "    df_res = pd.DataFrame(dtype = 'object')\n",
    "    df_res.at['name_params', name_reg] =\\\n",
    "                    str(list(param_grid.keys()))\n",
    "    df_res.at['best_params', name_reg] =\\\n",
    "                    str([scv.best_params_[p] for p in param_grid])\n",
    "\n",
    "    # score of the model with best params on testing set\n",
    "    ypr = scv.predict(Xte)\n",
    "    res = scores_reg(name_reg, Xte, yte, ypr,\n",
    "    \t             exclude=['Adj_R2']).astype('object')\n",
    "    df_res = df_res.append(res.to_frame())\n",
    "\n",
    "    # mean cv score of the model with best params on testing set\n",
    "    res = cv_scores_reg(name_reg, scv.best_estimator_,\n",
    "                        Xte, yte, cv=cv_test).astype('object')\n",
    "    df_res = df_res.append(res.to_frame())\n",
    "\n",
    "    return scv, df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = df[['Outlier', 'Neighborhood', 'CertifiedPreviousYear',\n",
    "               'NumberofFloors','ExtsurfVolRatio']]\n",
    "small_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_trans = ColumnTransformer([\n",
    "                                (\"bin\",  ce.BinaryEncoder(), ['CertifiedPreviousYear']),\n",
    "                                (\"ohe\", ce.BinaryEncoder(), ['Outlier']),\n",
    "                                (\"hash\", ce.BinaryEncoder() , ['Neighborhood']),\n",
    "                                # (\"num\", StandardScaler(), ['NumberofFloors','ExtsurfVolRatio']),\n",
    "                                ],\n",
    "                               remainder = 'passthrough')\n",
    "df_enc = cust_trans.fit_transform(small_df)\n",
    "cust_trans.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " small_df.shape, df_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_type_col(X, thresh_card=6):\n",
    "    bin_cols = (X.nunique()[X.nunique()<=2].index)\n",
    "    X_C_cols = X.select_dtypes(include=['object', 'category'])\n",
    "    C_l_card_cols = X_C_cols.nunique()[X_C_cols.nunique().between(3, thresh_card)].index\n",
    "    C_h_card_cols = X_C_cols.nunique()[X_C_cols.nunique()>thresh_card].index\n",
    "    Q_cols = [c for c in X.select_dtypes(include=[np.number]).columns\\\n",
    "                                                    if c not in bin_cols]\n",
    "    d_t = {'binary': bin_cols,\n",
    "            'low_card': C_l_card_cols,\n",
    "            'high_card': C_h_card_cols,\n",
    "            'numeric': Q_cols}\n",
    "    return d_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans =  DataFrameMapper([\n",
    "                                 (d_type_col(data)['binary'], ce.OrdinalEncoder()),\n",
    "                                 (d_type_col(data)['low_card'], ce.OneHotEncoder()),\n",
    "                                 (d_type_col(data)['high_card'], ce.OrdinalEncoder()),\n",
    "                                 (d_type_col(data)['numeric'], StandardScaler())\n",
    "                                 ],\n",
    "                                df_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'pet':      ['cat', 'dog', 'dog', 'fish', 'cat', 'dog', 'cat', 'fish'],\n",
    "                     'children': [4., 6, 3, 3, 2, 3, 5, 4],\n",
    "                     'index': ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'],\n",
    "                     'choice': ['0', '1', '1', '1', '0', '0', '1', '0'],\n",
    "                     'salary':   [90., 24, 44, 27, 32, 59, 36, 27]})\n",
    "data, d_type_col(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "\n",
    "ct_cat =  ColumnTransformer([\n",
    "                                 ('binary', ce.OrdinalEncoder(), d_type_col(X)['binary']),\n",
    "                                 ('low_card', ce.OneHotEncoder(), d_type_col(X)['low_card']),\n",
    "                                 ('high_card', ce.HashingEncoder(), d_type_col(X)['high_card']),\n",
    "                                #  ('numeric', StandardScaler(), d_type_col(X)['numeric'])\n",
    "                                 ], remainder='passthrough')\n",
    "\n",
    "num_cols = d_type_col(X)['numeric']\n",
    "num_trans = Pipeline([(\"numeric\", StandardScaler())])\n",
    "\n",
    "cat_cols = d_type_col(X)['binary'].union(d_type_col(X)['low_card']).union(d_type_col(X)['high_card'])\n",
    "cat_trans = Pipeline([(\"categ\", ct_cat)])\n",
    "\n",
    "column_trans =  ColumnTransformer([\n",
    "                                   ('cat', cat_trans, cat_cols),\n",
    "                                   ('num', num_trans, num_cols),\n",
    "                                   ], remainder='passthrough')\n",
    "                                                \n",
    "column_trans.fit(data)\n",
    "cat_trans.fit(data)\n",
    "ct_cat.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "class CustTransformer(BaseEstimator) :\n",
    "\n",
    "    def __init__(self, thresh_card=12,\n",
    "                 strat_binary = 'ord', strat_low_card ='ohe',\n",
    "                 strat_high_card ='hash', strat_quant = 'stand'):\n",
    "        self.thresh_card = thresh_card\n",
    "        self.strat_binary = strat_binary\n",
    "        self.strat_low_card = strat_low_card\n",
    "        self.strat_high_card = strat_high_card\n",
    "        self.strat_quant = strat_quant\n",
    "\n",
    "    def d_type_col(self, X):\n",
    "        bin_cols = (X.nunique()[X.nunique()==2].index)\n",
    "        X_C_cols = X.select_dtypes(include=['object', 'category'])\n",
    "        C_l_card_cols = X_C_cols.nunique()[X_C_cols.nunique()<self.thresh_card].index\n",
    "        C_h_card_cols = X_C_cols.nunique()[X_C_cols.nunique()>=self.thresh_card].index\n",
    "        Q_cols = [c for c in X.select_dtypes(include=[np.number]).columns\\\n",
    "                                                        if c not in bin_cols]\n",
    "        d_t = {'binary': bin_cols,\n",
    "               'low_card': C_l_card_cols,\n",
    "               'high_card': C_h_card_cols,\n",
    "               'remaind': Q_cols}\n",
    "        return d_t\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Dictionary to translate strategies\n",
    "        d_enc = {'ohe': ce.OneHotEncoder(),\n",
    "                 'hash': ce.HashingEncoder(),\n",
    "                 'ord': ce.OrdinalEncoder(),\n",
    "                 'loo': ce.LeaveOneOutEncoder(),\n",
    "                 'bin': ce.BinaryEncoder(),\n",
    "                 'stand': StandardScaler(),\n",
    "                 'minmax': MinMaxScaler(),\n",
    "                 'maxabs': MaxAbsScaler(),\n",
    "                 'robust': RobustScaler(quantile_range=(25, 75)),\n",
    "                 'norm': Normalizer(),\n",
    "                 'quant_uni': QuantileTransformer(output_distribution='uniform'),\n",
    "                 'quant_norm': QuantileTransformer(output_distribution='normal'),\n",
    "                 'pow': PowerTransformer(method='yeo-johnson'), # 'boxcox'\n",
    "                 }\n",
    "        # Creates a columns transformer with chosen strategies\n",
    "        self.column_trans = \\\n",
    "                ColumnTransformer([(\"binary\", d_enc[self.strat_binary],\n",
    "                                    self.d_type_col(X)['binary']),\n",
    "                                   (\"low_card\", d_enc[self.strat_low_card],\n",
    "                                    self.d_type_col(X)['low_card']),\n",
    "                                   (\"high_card\", d_enc[self.strat_high_card],\n",
    "                                    self.d_type_col(X)['high_card']),\n",
    "                                   (\"remaind\", d_enc[self.strat_quant],\n",
    "                                    self.d_type_col(X)['remaind'])])\n",
    "        return self.column_trans.fit(X, y)\n",
    "  \n",
    "    def transform(self, X, y=None):\n",
    "        return  self.column_trans.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers = df[df['Outlier']!='not']\n",
    "df_outliers_h = df[df['Outlier']=='high']\n",
    "df_outliers_l = df[df['Outlier']=='low']\n",
    "sns.scatterplot(data = df, x='PropertyGFATotal', y= 'SiteEnergyUseWN(kBtu)', color='k', size=1, edgecolor=None)\n",
    "sns.scatterplot(data = df_outliers, x='PropertyGFATotal', y= 'SiteEnergyUseWN(kBtu)',\n",
    "                hue='Outlier', size=1, edgecolor=None)\n",
    "plt.gca().legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perm_importance(model, X, y, scoring='r2'):\n",
    "\n",
    "    results = permutation_importance(model, X, y, scoring=scoring) \n",
    "    df_ = pd.DataFrame(results.importances_mean,\n",
    "                       index = X.columns, columns=[name_reg])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    df_[name_reg].sort_values(ascending=False).plot.bar(color='grey')\n",
    "    fig.set_size_inches(12,3)\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha=\"right\" )\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleAndFeatureFilter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, perc = None):\n",
    "        self.perc = perc\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.X = X\n",
    "        sum_per_feature = X.sum(0)\n",
    "        sum_per_sample = X.sum(1)\n",
    "        self.featurefilter = sum_per_feature >= np.percentile(sum_per_feature, self.perc)\n",
    "        self.samplefilter = sum_per_sample >= np.percentile(sum_per_sample, self.perc)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, copy=None):\n",
    "        idx = id(X)\n",
    "        X=X[:,self.featurefilter]\n",
    "        if idx == id(self.X):\n",
    "            X = X[self.samplefilter, :]\n",
    "            if y is not None:\n",
    "                y = y[self.samplefilter]\n",
    "            return X, y\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        if y is None:\n",
    "            return self.fit(X, **fit_params).transform(X)\n",
    "        else:\n",
    "            return self.fit(X, y, **fit_params).transform(X,y)\n",
    "\n",
    "class Pipeline_Xy(Pipeline):\n",
    "    def _pre_transform(self, X, y=None, **fit_params):\n",
    "        fit_params_steps = dict((step, {}) for step, _ in self.steps)\n",
    "        for pname, pval in items(fit_params):\n",
    "            step, param = pname.split('__', 1)\n",
    "            fit_params_steps[step][param] = pval\n",
    "        Xt = X\n",
    "        yt = y\n",
    "        for name, transform in self.steps[:-1]:\n",
    "            if hasattr(transform, \"fit_transform\"):\n",
    "                res = transform.fit_transform(Xt, yt, **fit_params_steps[name])\n",
    "                if len(res) == 2:\n",
    "                    Xt, yt = res\n",
    "                else:\n",
    "                    Xt = res\n",
    "            else:\n",
    "                Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n",
    "                              .transform(Xt)\n",
    "        return Xt, yt, fit_params_steps[self.steps[-1][0]]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        Xt, yt, fit_params = self._pre_transform(X, y, **fit_params)\n",
    "        self.steps[-1][-1].fit(Xt, yt, **fit_params)\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        Xt, yt, fit_params = self._pre_transform(X, y, **fit_params)\n",
    "        if hasattr(self.steps[-1][-1], 'fit_transform'):\n",
    "            return self.steps[-1][-1].fit_transform(Xt, yt, **fit_params)\n",
    "        else:\n",
    "            return self.steps[-1][-1].fit(Xt, yt, **fit_params).transform(Xt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COEFF IMPORTANCE OF THE FEATURES\n",
    "\n",
    "# Getting the names of the transformed columns\n",
    "step_ct = dict_models[name_reg].best_estimator_.named_steps['preproc'].named_steps['cust_trans']\n",
    "col_names = step_ct.get_feature_names() #dict_scv_params['X']\n",
    "# Getting the list of the coefficients\n",
    "col_coefs = dict_models[name_reg].best_estimator_.named_steps[name_reg].coef_\n",
    "\n",
    "ser = pd.Series(col_coefs, index = col_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ser.sort_values(ascending=False).plot.bar(color='red');\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha=\"right\" )\n",
    "fig.set_size_inches(15,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
